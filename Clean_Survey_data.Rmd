---
title: "Warum du deine Online-Befragungsdaten bereinigen solltest"
author: "Thomas Halamuda"
date: "21 5 2020"
output:
  word_document: default
  pdf_document: default
  html_document: default
---



### 1. Wann ist der Artikel für dich relevant?
Du hast eine gerade eine Online-Studie erhoben, etwa aus einem Online-Access Panel (OAP) und möchtest die Daten analysieren. Der Artikel beantwortet dir folgende Fragen:
-	Ist ein Cleaning der Daten überhaupt notwendig?
-	Welche Analysen sollte ich vornehmen?
-	Ist es den Aufwand wert?


### 2. Deine Motivation
Stellt Dir vor Du befindest dich an einer Straßenkreuzung in Florenz und fragst einen Passanten nach dem Weg zum Palazzo Vechio? Wonach beurteilst du diesen Passanten? Ganz intuitiv musterst du die Person danach, ob sie, 
-	nicht zu beschäftigt, 
-	Aufgeschlossen und ehrlich,
-	Und kompetent ist.
Bei deiner Befragung gehst du nicht anders vor, nur mit dem Unterschied, dass du nciht deine 5 Sinne zur Verfügung hast, sondern lediglich die Daten vor Dir. Diese 3 Befragungstypen sollten daher im finalen Datensatz eliminiert werden, denn:  Kein Rat ist besser als schlechter Rat!

1.	Der Bounty Hunter: Dieser Typ tritt am häufigsten auf. Er hat kein grundlegendes Interesse an der Befragung, für Ihn geht es ausschließlich um die ausgeschütteten Incentives des Panelbetreiber, wie Gutscheine, Schecks etc..
Er versucht aufgrund seines Fokus auf das Incentive, die Befragung in der Regel möglichst schnell und mit wenig Aufwand abzuschließen, an der Befragung hat er aber kein Interesse.  Im Grunde handelt er wie ein rationaler Unternehmer, manche neigen sogar dazu, zu Täuschen und zu betrügen, um das Incentive schneller zu erhalten. 
2.	Der Troll: Er möchte die Befragung gezielt manipulieren und „Schaden“ anrichten. In der Regel ist nicht erkennbar, warum er die Studie torpedieren möchte. Die Motive blieben für den Analysten also „irrational“.
3.	Der Überforderte: Diese Person ist von (Teilen) der Befragung überfordert und gibt Antworten auf Fragen, die er nicht versteht. Ursache ist hierfür der Fragebogen selbst und nicht die Motivation des Befragten! Der Fehler ist also bereits beim Studien- und Fragebogendesign entstanden!

Abhängig von dem OAP, dem Studien- und Fragebogendesign würde ich die Quote an nicht erwünschten Panelisten, selbst bei qualitativ hochwertigen Studien, zwischen 3% und 15% schätzen. 



### 2. Was du tun kannst.

Analsiere den Datensatzes anhand der:  
1. Befragungszeit,
2. Varianz,
3. Konsistenz im Antwortverhalten,

Anhand eines typischen Datensatzes werden die Maßnahmen zur Erkennung „schlechter“ Befragter dargestellt und bewertet. Der gesamte R-Code kann unter folgendem GitHub-Repo nachvollzuogen werden: 
https://github.com/Vogelweide1985/Clean_survey_data_of_OAPs


### 3. Zeit ist kostbar – für jeden von uns!

Die Analyse der Befragungszeit einer Person ist mit Abstand die wichtigste Variable. Warum? Insgesamt ist die verbliebene Zeit im Fragebogen ein Indikator für das Maß an Interesse des Befragten. Vor allem Der Bounty Hunter hat ein Interesse daran, die Studie möglichst schnell abzuschließen, um sein Return on Investment (ROI) pro Studie zu erhöhen. Einige wissen jedoch, dass Sie es nicht übertreiben dürfen und achten darauf, es mit dem „Durchklicken“ nicht zu übertreiben.  
Fangen wir mit der einfachsten Analyse an: 


```{r options, include = FALSE}
knitr::opts_chunk$set(echo = F)
knitr::opts_chunk$set(warning = F)
```

```{r init, include = FALSE}

library(tidyverse)
library(lubridate)
library(knitr)

source("corporate_design.R")

#Load Data
df <- readRDS("./public_data/survey.rds")

```


```{r preprocessing}
#Renaming cols
colnames(df) <- gsub("Zeitstempel", "timestamp", colnames(df))

#Transmute timestamps to lubridate duration
df <- df %>%
      mutate_at(vars(starts_with("timestamp")), duration) 


#Create unique ID
df$id <- 1:length(1:nrow(df))
```

Zunächst erstellen wir uns einen Klassicshen Boxplot:

```{r first_plot}

#Plot Boxplot
ggplot(df, aes(y=dminutes(timestamp_5))) + geom_boxplot( color= cd_main[1]) +cd_theme()  + 
  ggtitle("Petal and sepal length of iris") + labs(y="Petal length (cm)", x = "Sepal length (cm)")
```

Ups! Manchmal hat man eine Visualisierung in Kopf, die am Ende nicht funktioniert. Setzt man einen Summary Befehl auf sieht man, dass einige Personen sehr sehr lange für die Befragung gebraucht haben. 
Man beachte die große Diskrepanz zwischen dem Median und dem Mittelwert. In der Regel ist der Mittelwert also ein schlechter Referenzwert, stattdessen sollte eher der Median betrachtet werden. 
```{r summary_stats_total}
kable(summary(df$timestamp_5), col.names = "Lagemaße")
#kable(quantile(df$timestamp_5, seq(0, 1, 0.1)))
```

Der maximal Wert liegt in dieser Studie bei einer Woche, d.h. die Personen hat die Befragung nach 7 Tagen wieder aufgenommen! Ein Klassiker, denn einige Personen unterbrechen die Befragung für längere Zeit um sie später wieder aufzunehmen. Wir kommen gleich dazu, wie man mit diesen Personen umgeht.

Der Scatter Plot verdeutlicht nochmal diesen Sachverhalt: Auf der X-Achse sind die individuellen Befragten abgebildet auf der Y-Achse die benötigte Zeit in Sekunden.
```{r scatter_total_plot}
ggplot(df, aes(x=id, y= dminutes(timestamp_5))) + geom_point(color = cd_main[1]) +cd_theme() 
```

Die prinzipielle Vorgehensweise lautet, erstmal alle Verdächtigen Befragten zu "taggen". Bei der Zeitstempelanalyse gibt es verschiedene Möglichkeiten:
- Tags setzen anhand von Min/Max- Grenzen nach inhaltlichen Kriterien oder Erfahrungswerten. Z.b. Alle Personen taggen unter 5 Minuten und über 45 Minuten. 
- Tags setzen anhand statistischer Maßgaben. Z.B. Extremwerte/Außreiser laut Boxplot Berechnung oder Quantilen.

Exemplarischen werden jetzt folgende Tags gesetzt

```{r tag_time_total, echo = T}
q <- quantile(df$timestamp_5, seq(0,1, 0.05)) # Get Quantile
df$tag_time_under_5 <- ifelse(df$timestamp_5 <= dminutes(5), 1, 0 )
df$tag_time_over_45 <- ifelse(df$timestamp_5 >= dminutes(30), 1, 0 )
df$tag_time_over_60 <- ifelse(df$timestamp_5 >= dminutes(45), 1, 0 )
df$tag_time_under_q05 <-  ifelse(df$timestamp_5 <= q[1], 1, 0 ) # Alle im unteren 5% Quantil
df$tag_time_under_q10 <-  ifelse(df$timestamp_5 <= q[2], 1, 0 ) # Alle im unteren 10% Quantil
df$tag_time_under_q15 <-  ifelse(df$timestamp_5 <= q[3], 1, 0 ) # Alle im unteren 1% Quantil
df$tag_time_over_q95 <-  ifelse(df$timestamp_5 >= q[20], 1, 0 ) # Alle im unteren 1% Quantil
df$tag_time_over_q90 <-  ifelse(df$timestamp_5 >= q[19], 1, 0 ) # Alle im unteren 1% Quantil
df$tag_time_over_q85 <-  ifelse(df$timestamp_5 >= q[18], 1, 0 ) # Alle im unteren 1% Quantil
```

Meist sind solche Tags schon vollkomen ausreichend. Wie schnell ein Fragebogen absolviert werden kann, wird immer ein Stück subjektiv bleiben!

```{r barplot_n}

```


Doch Vorsicht: Die Befragungszeit hängt von vielen Faktoren ab, die es manchmal Wert sind berücksichtigt zu werden. Z.b. Sind die "Digital Natives", also die jüngeren in der Regel schneller im Antwortverhalten als 60 Jährige. Eines der wichtigsten Fehlerquellen ist es: Wenn aufgrund der Fragebogenstruktur eine Befragte größere Frageblöcke gar nicht gesehen haben, dann ist es auch klar, dass sie den Fragebogen schneller durchgehen konnten! Dies würde die Ergebnisse massiv verfälschen. 

Um dies zu deutlichen betrachte man die Boxplots nach Alter und einer Filtervariable, die dafür sorgt, dass der Befragte einige Medienfragen überspringt. Der Datensatz wurde zur besseren übersicht nur auf Personen unter 30 Minuten beschränkt.



```{r tag_time_total_split}
df %>%
  filter(timestamp_5 <= dminutes(30)) %>%
  ggplot(aes(y=timestamp_5, x= as.factor(age_group) ,fill= as.factor(media_filter))) + geom_boxplot(fill= cd_main[1:3])  +
  cd_theme() 


```

Die Grafik zeigt deutlich, dass der Befragungsfilter für kürzere Antwortzeiten sorgt! Würde man an dieser Stelle bei den "Turbos"zu stark aussieben erhält man zu hohe Werte in der Mediennnutzung! 